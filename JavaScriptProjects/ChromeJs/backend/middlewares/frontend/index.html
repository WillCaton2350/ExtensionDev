<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <title>Volume Control Extension</title>
</head>

<body>
    <h1>Volume Controller</h1>
    <h2>ðŸ”Š</h2>
    <button onclick="activate()" class="btn">Start</button>
    <video class="video-tag" id="videoElement" width="640" height="480" autoplay></video>
    <script>
        function onHandTrackingModuleReady() {
            console.log('HandTrackingModule is ready.');
        }
    </script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@mediapipe/hands" onload="onHandTrackingModuleReady();"></script>
    <script src="./hands_solution_packed_assets_loader.js"></script>
    <script src="./hands_solution_simd_wasm_bin.js"></script>
    <script async src="https://docs.opencv.org/master/opencv.js" onload="onOpenCvReady()" onerror="console.error('Error loading OpenCV.');" type="text/javascript"></script>
    <script>
        const mediapipeVideoElement = document.getElementById('videoElement');
        const hands = new Hands({ video: mediapipeVideoElement });
        hands.initialize();

        const startCamera = async () => {
            const videoStream = await navigator.mediaDevices.getUserMedia({ video: {} });
            mediapipeVideoElement.srcObject = videoStream;
            hands.start();
        };

        startCamera();

        hands.onResults((results) => {
            if (!results.multiHandLandmarks) {
                return;
            }

            results.multiHandLandmarks.forEach((handLandmarks) => {

                let indexFingerTip = handLandmarks[8];

              
                let imageWidth = mediapipeVideoElement.width;
                let imageHeight = mediapipeVideoElement.height;

                let pixelX = indexFingerTip.x * imageWidth;
                let pixelY = indexFingerTip.y * imageHeight;

       
                let length = Math.hypot(pixelX - handLandmarks[4].x, pixelY - handLandmarks[4].y);
                if (length < 40) {

                    let targetVolume = interp(length, [40, 200], [volumeMin, volumeMax]);
                    let step = 58;

                    if (currentVolume < targetVolume) {
                        currentVolume = Math.min(currentVolume + step, targetVolume);
                    } else if (currentVolume > targetVolume) {
                        currentVolume = Math.max(currentVolume - step, targetVolume);
                    }

                    changeVolume(currentVolume);
                    console.log(`Volume set to ${currentVolume}`);
                }
            });
        });

        function onOpenCvReady() {
            cvCap = new cv.VideoCapture(mediapipeVideoElement);
            cvDetector = new HandTrackingModule.HandDetector(1, 0.3);
            volumeMin = 0;
            volumeMax = 100;
            currentVolume = volumeMin;
            processVideo();
        }

        function changeVolume(volume) {
            const script = `osascript -e 'set volume output volume ${volume}'`;
            cv.utils.executeFile(script, (error, stdout, stderr) => {
                if (error) {
                    console.error(`Error changing volume: ${stderr}`);
                } else {
                    console.log(`Volume changed on the server: ${volume}`);
                }
            });
        }

        function processVideo() {
            let begin = Date.now();
            let img = new cv.Mat();
            cvCap.read(img);
            let hands = cvDetector.findHands(img, false);
            hands.forEach(hand => {
                let { x, y, width, height } = hand.bbox;
                cv.rectangle(img, new cv.Point(x, y), new cv.Point(x + width, y + height), [0, 255, 0, 255], 2);

                let length = Math.hypot(hand.lmList[8][0] - hand.lmList[4][0], hand.lmList[8][1] - hand.lmList[4][1]);
                if (length < 40) {
                    cv.circle(img, new cv.Point(hand.lmList[8][0], hand.lmList[8][1]), 10, [0, 255, 0, 255], cv.FILLED);
                }

                let targetVolume = cv.interp(length, [40, 200], [volumeMin, volumeMax]);
                let step = 58;

                if (currentVolume < targetVolume) {
                    currentVolume = Math.min(currentVolume + step, targetVolume);
                } else if (currentVolume > targetVolume) {
                    currentVolume = Math.max(currentVolume - step, targetVolume);
                }

                changeVolume(currentVolume);
                console.log(`Volume set to ${currentVolume}`);
            });

            cv.imshow('videoElement', img);
            cv.putText(img, `FPS: ${Math.round(1000 / (Date.now() - begin))}`, new cv.Point(50, 70), cv.FONT_HERSHEY_SIMPLEX, 1, [255, 0, 0, 255], 2);
            requestAnimationFrame(processVideo);
        }

        function activate() {
            console.log("Button clicked!");
            if (typeof cv === 'undefined' || typeof HandTrackingModule === 'undefined') {
                console.error('OpenCV or HandTrackingModule not loaded correctly.');
                return;
            }
            if (!cvCap || cvCap.read().empty()) {
                navigator.mediaDevices.getUserMedia({ video: true })
                    .then(stream => {
                        mediapipeVideoElement.srcObject = stream;
                        cvCap = new cv.VideoCapture(mediapipeVideoElement);
                        cvCap.set(cv.CAP_PROP_FRAME_WIDTH, 640);
                        cvCap.set(cv.CAP_PROP_FRAME_HEIGHT, 480);

                        setTimeout(() => {
                            processVideo();
                        }, 1000);
                    })
                    .catch(error => {
                        console.error('Error accessing camera:', error);
                    });
            }
        }
    </script>
</body>

</html>
